---
title: "Stochastic Mode: Policy Search"
subtitle: "Robust optimization with Monte Carlo"
engine: julia
execute:
  exeflags: ["--project=.."]
---

## Overview

This guide shows how to use stochastic simulation for robust policy optimization.
While EAD mode is faster, stochastic mode can capture tail risk and scenario-specific effects.

## Setup

```{julia}
#| output: false
using ICOW
using Distributions
using Random
import Metaheuristics
using DataFrames
using CairoMakie
```

```{julia}
# Setup
rng = Random.MersenneTwister(42)
city = CityParameters()

# Generate scenarios
num_scenarios = 50  # Fewer for optimization speed
num_years = 50
surge_dist = GeneralizedExtremeValue(1.0, 0.5, 0.1)
surges = rand(rng, surge_dist, num_scenarios, num_years)
stoch_forcing = StochasticForcing(surges)
```

## Optimization Setup

For optimization, we create an EAD forcing from the same distribution.
The optimizer uses EAD mode for speed, but we can verify results with stochastic mode:

```{julia}
# EAD forcing for optimization
ead_forcing = DistributionalForcing([surge_dist for _ in 1:num_years])
```

## Running the Optimizer

```{julia}
#| output: false
result = ICOW.optimize(
    city,
    [ead_forcing],
    0.0;  # discount rate
    max_iterations=50,
    population_size=30
)
```

## Pareto-Optimal Policies

```{julia}
policies = pareto_policies(result, StaticPolicy{Float64})
println("Found $(length(policies)) Pareto-optimal solutions")
```

## Verifying with Stochastic Mode

Let's verify the best policy using stochastic simulation:

```{julia}
best, best_obj = best_total(result, StaticPolicy{Float64})

# Run stochastic verification
stoch_damages = map(1:num_scenarios) do s
    _, dmg = simulate(city, best, stoch_forcing; scenario=s, rng=rng)
    dmg
end

println("Best Policy Verification:")
println("  EAD damage: \$$(round(best_obj.mean_damage/1e9, digits=2)) billion")
println("  Stochastic mean: \$$(round(mean(stoch_damages)/1e9, digits=2)) billion")
println("  Stochastic std: \$$(round(std(stoch_damages)/1e9, digits=2)) billion")
```

## Comparing Pareto Points

Let's compare EAD vs stochastic for several Pareto-optimal policies:

```{julia}
comparison = map(policies[1:min(5, length(policies))]) do (policy, obj)
    # Stochastic evaluation
    stoch_dmgs = map(1:num_scenarios) do s
        _, dmg = simulate(city, policy, stoch_forcing; scenario=s, rng=rng)
        dmg
    end

    l = policy.levers
    (
        D = round(l.D, digits=1),
        ead_dmg = round(obj.mean_damage/1e9, digits=2),
        stoch_mean = round(mean(stoch_dmgs)/1e9, digits=2),
        stoch_std = round(std(stoch_dmgs)/1e9, digits=2),
        stoch_p95 = round(quantile(stoch_dmgs, 0.95)/1e9, digits=2)
    )
end

DataFrame(comparison)
```

## Risk-Aware Policy Selection

While the Pareto frontier is based on expected values, stochastic mode reveals tail risk.
A risk-averse decision-maker might prefer a policy with:

- Lower 95th percentile damage (less tail risk)
- Lower standard deviation (more predictable outcomes)

```{julia}
#| label: fig-risk
#| fig-cap: "Risk comparison of Pareto-optimal policies"
#| code-fold: true
let
    # Evaluate all Pareto policies
    risk_data = map(policies) do (policy, obj)
        stoch_dmgs = map(1:num_scenarios) do s
            _, dmg = simulate(city, policy, stoch_forcing; scenario=s, rng=rng)
            dmg
        end
        (
            investment = obj.mean_investment/1e9,
            mean_damage = mean(stoch_dmgs)/1e9,
            p95_damage = quantile(stoch_dmgs, 0.95)/1e9
        )
    end

    fig = Figure(size=(600, 500))
    ax = Axis(fig[1, 1];
        xlabel="Investment Cost (\$ billions)",
        ylabel="Damage (\$ billions)",
        title="Mean vs 95th Percentile Damage"
    )

    investments = [r.investment for r in risk_data]
    means = [r.mean_damage for r in risk_data]
    p95s = [r.p95_damage for r in risk_data]

    scatter!(ax, investments, means;
        marker=:circle, markersize=10, color=:steelblue, label="Mean Damage")
    scatter!(ax, investments, p95s;
        marker=:diamond, markersize=10, color=:coral, label="95th Percentile")

    axislegend(ax; position=:rt)
    fig
end
```

## When to Use Stochastic Optimization

| Scenario | Recommendation |
|----------|----------------|
| Fast screening | Use EAD for optimization |
| Final validation | Verify with stochastic |
| Risk-sensitive decisions | Optimize with stochastic objectives |
| Climate scenarios | Use stochastic with varied forcings |

## Summary

1. **EAD optimization is efficient** for finding Pareto-optimal policies
2. **Stochastic verification** confirms EAD results and quantifies uncertainty
3. **Risk metrics** (std, percentiles) help risk-averse decision-making
4. Both modes converge to the same expected values

## Next Steps

- [Getting Started](getting_started.qmd) - Review model fundamentals
- [EAD Analysis](ead_analysis.qmd) - Fast policy comparison
